{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Regresion_Lineal_Cruda.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNN1/+aVBhJiv4/pQs1ZLc9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/renatojobal/regresion_linear_cruda/blob/master/Regresion_Lineal_Cruda.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "se15supPwkuc",
        "colab_type": "code",
        "outputId": "260a63b9-36eb-47de-f506-fd7d4b68a662",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "x = np.array([ x+random.uniform(0,1) for x in range(0,10)])\n",
        "y = np.array([ y+random.uniform(0,1) for y in range(0,10)])\n",
        "\n",
        "#Compute prediction\n",
        "defprediction(w,b,x):\n",
        "  return w*x+b\n",
        "\n",
        "n = len(y) \n",
        "\n",
        "#Compute loss function and gradient's\n",
        "defloss_function(y,y_p):\n",
        "  return (1/n)* sum([val**2for val in (y-y_p)])\n",
        "\n",
        "defw_slope(y,y_p,x):\n",
        "  return -(2/n)*sum(x*(y-y_p))\n",
        "\n",
        "defb_slope(y,y_p,x):\n",
        "  return -(2/n)*sum(y-y_p)\n",
        "\n",
        "#Define new Steps to change the values of w & b\n",
        "defw_new(y,y_p,x,w,lr):\n",
        "  return w - lr* w_slope(y,y_p,x)\n",
        "defb_new(y,y_p,x, b,lr):\n",
        "  return b - lr* b_slope(y,y_p,x)\n",
        "\n",
        "#Starting values for w & b\n",
        "defgradient_descent(y,x,w,b, lr):\n",
        "\n",
        "  y_prediction = []\n",
        "  w_values=[]\n",
        "  b_values=[]\n",
        "  loss_values = []\n",
        "\n",
        "  iterations = 1000\n",
        "  for i in range(iterations):\n",
        "    y_pred = prediction(w,b,x)\n",
        "    w = w_new(y,y_pred,x,w,lr)\n",
        "    b = b_new(y,y_pred,x,b,lr)\n",
        "    Loss = loss_function(y,y_pred) \n",
        "\n",
        "    y_prediction.append(y_pred)\n",
        "    w_values.append(w)\n",
        "    b_values.append(b)\n",
        "    loss_values.append(Loss)\n",
        "\n",
        "    print(f'w={w}, b={b}, loss = {loss_function(y,y_pred)}, i = {i}')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  w=b=0\n",
        "  lr=0.0259\n",
        "  gradient_descent(y,x,w,b,lr)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-51b34f5458cd>\"\u001b[0;36m, line \u001b[0;32m9\u001b[0m\n\u001b[0;31m    defprediction(w,b,x):\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    }
  ]
}